## Step 1: Inspect Your Data Source

## Step 2: Scrape HTML Content From a Page

import requests
from bs4 import BeautifulSoup

URL = "https://realpython.github.io/fake-jobs/"
page = requests.get(URL)

## Step 3: Parse HTML Code With Beautiful Soup

soup = BeautifulSoup(page.content, "html.parser")

## The second argument, "html.parser", makes sure that you use the appropriate parser for HTML content

results = soup.find(id="ResultsContainer")

## The element youâ€™re looking for is a <div> with an id attribute that has the value "ResultsContainer"

print(results.prettify())

job_elements = results.find_all("div", class_="card-content")

for job_element in job_elements:
    title_element = job_element.find("h2", class_="title")
    company_element = job_element.find("h3", class_="company")
    location_element = job_element.find("p", class_="location")
    print(title_element.text.strip())
    print(company_element.text.strip())
    print(location_element.text.strip())
    print()
    
python_jobs = results.find_all (
    "h2", string=lambda text: "python" in text.lower()
)


## the lambda function looks at the text of each <h2> element, converts it to lowercase, 
## and checks whether the substring "python" is found anywhere


python_job_elements = [
    h2_element.parent.parent.parent for h2_element in python_jobs
]

for job_element in python_job_elements:
    link_url = job_element.find_all("a")[1]["href"]
    print(f"Apply here: {link_url}\n")
